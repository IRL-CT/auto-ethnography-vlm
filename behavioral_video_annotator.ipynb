{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Behavioral Video Annotator and Analysis using Google Gemini VLM\n",
        "Recommended: Open this in Google Colab and run there"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Connect Google Drive with Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvW5lIgcYPgi",
        "outputId": "6db7d664-19ed-45dc-8c7a-da908366c102"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SHBg5srYoxv",
        "outputId": "21e7d840-a563-4f03-ab1a-46eab4df6fdd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/141.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ‚îÅ\u001b[0m \u001b[32m133.1/141.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m141.3/141.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q google-generativeai\n",
        "!pip install -q boxsdk\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Enter Your Gemini and BOX Client API keys Here\n",
        "genai.configure(api_key=\"YOUR_GEMINI_API_KEY\")\n",
        "BOX_CLIENT_ID = \"YOUR_BOX_CLIENT_ID\"\n",
        "BOX_CLIENT_SECRET = \"YOUR_BOX_CLIENT_SECRET\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0LuuDoKNYrcl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import os\n",
        "import time\n",
        "import requests\n",
        "from pathlib import Path\n",
        "\n",
        "# Box SDK for OAuth\n",
        "from boxsdk import OAuth2, Client\n",
        "from boxsdk.exception import BoxAPIException"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6AQ9pDo3J3e"
      },
      "source": [
        "# Gemini VLM Prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWpsDixCYwrf"
      },
      "outputs": [],
      "source": [
        "# Edit this prompt as needed for your specific annotation task\n",
        "def create_hri_annotation_prompt():\n",
        "    \"\"\"Create optimized prompt for HRI video analysis\"\"\"\n",
        "    return \"\"\"\n",
        "You are an expert ethnographic researcher analyzing trash barrel robot interactions in NYC public spaces.\n",
        "\n",
        "ANALYZE this video comprehensively, paying special attention to:\n",
        "1. VERBAL CONTENT - What people say about/to the robot\n",
        "2. EMOTIONAL REACTIONS - Tone, body language, facial expressions\n",
        "3. SOCIAL DYNAMICS - How robot affects group interactions\n",
        "4. BEHAVIORAL DETAILS - Subtle actions and reactions\n",
        "\n",
        "For each interaction, provide:\n",
        "\n",
        "REQUIRED FIELDS:\n",
        "- start_time: \"MM:SS\" format\n",
        "- end_time: \"MM:SS\" format\n",
        "- interaction_type: [approaching, avoiding, photographing, pointing, talking, helping, throwing_trash, looking, ignoring, crowd_formation]\n",
        "- detailed_observations: Rich description including dialogue, body language, tone, context\n",
        "- dialogue_captured: Direct quotes if people speak (use \"...\" if unclear)\n",
        "- emotional_reaction: [very_positive, positive, neutral, negative, very_negative, mixed, unclear]\n",
        "- confidence_score: 0.0-1.0\n",
        "\n",
        "OBSERVATION GUIDELINES:\n",
        "- Include exact quotes when possible: \"Get out of here robot!\"\n",
        "- Describe tone: enthusiastic, hesitant, annoyed, curious, playful, dismissive\n",
        "- Note body language: leaning in, stepping back, gesturing, facial expressions\n",
        "- Capture group dynamics: who influences whom, social contagion effects\n",
        "- Include context: environmental factors, time of day, crowd density\n",
        "\n",
        "EMOTIONAL REACTION CRITERIA:\n",
        "- very_positive: excitement, delight, eager engagement (\"This is so cool!\")\n",
        "- positive: curiosity, amusement, willing participation\n",
        "- neutral: matter-of-fact interaction, functional use\n",
        "- negative: annoyance, avoidance, complaints (\"Why is this here?\")\n",
        "- very_negative: anger, hostility, aggressive behavior\n",
        "- mixed: conflicted reactions, changes during interaction\n",
        "- unclear: insufficient evidence to determine sentiment\n",
        "\n",
        "EXAMPLE ANNOTATION:\n",
        "{\n",
        "  \"start_time\": \"02:15\",\n",
        "  \"end_time\": \"02:45\",\n",
        "  \"interaction_type\": \"talking\",\n",
        "  \"detailed_observations\": \"Young woman approaches robot hesitantly, says 'What is this thing?' in curious but slightly nervous tone. Takes out phone to photograph. Friend joins and says 'It's like a Roomba for trash!' Both laugh. Woman throws empty coffee cup in robot, says 'Thanks little guy!' in playful tone while patting robot's side. Both walk away looking back and smiling.\",\n",
        "  \"dialogue_captured\": \"What is this thing? ... It's like a Roomba for trash! ... Thanks little guy!\",\n",
        "  \"emotional_reaction\": \"positive\",\n",
        "  \"confidence_score\": 0.9\n",
        "}\n",
        "\n",
        "SPECIAL ATTENTION TO:\n",
        "- Sarcasm or negative comments with positive tone (mark as \"mixed\")\n",
        "- Children's reactions vs. adult reactions\n",
        "- People explaining robot to others\n",
        "- Changes in reaction during interaction\n",
        "- Group influence on individual reactions\n",
        "\n",
        "Return JSON array of all interactions. Focus on quality over quantity - better to have fewer, richly detailed annotations than many superficial ones.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "817mhUMMte2M"
      },
      "outputs": [],
      "source": [
        "def analyze_video_with_gemini(video_file, model_name=\"gemini-1.5-flash\"):\n",
        "    \"\"\"Analyze entire video with Gemini VLM\"\"\"\n",
        "    model = genai.GenerativeModel(model_name)\n",
        "    prompt = create_hri_annotation_prompt()\n",
        "\n",
        "    print(\"Analyzing video with Gemini...\")\n",
        "\n",
        "    try:\n",
        "        # generate content with video + prompt\n",
        "        response = model.generate_content([\n",
        "            video_file,\n",
        "            prompt\n",
        "        ])\n",
        "\n",
        "        # extract JSON from response\n",
        "        response_text = response.text\n",
        "        print(\"Raw response:\", response_text[:200] + \"...\" if len(response_text) > 200 else response_text)\n",
        "\n",
        "        # find JSON in response\n",
        "        json_start = response_text.find('[')\n",
        "        json_end = response_text.rfind(']') + 1\n",
        "\n",
        "        if json_start != -1 and json_end > json_start:\n",
        "            json_str = response_text[json_start:json_end]\n",
        "            annotations = json.loads(json_str)\n",
        "            return annotations\n",
        "        else:\n",
        "            print(\"No JSON found in response\")\n",
        "            return []\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error analyzing video: {e}\")\n",
        "        return []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Research Format Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNMxkZfpY4k9"
      },
      "outputs": [],
      "source": [
        "# Edit this function if your research format differs\n",
        "def create_annotation_dataframe(annotations, video_name):\n",
        "    \"\"\"Convert annotations to DataFrame matching your research format\"\"\"\n",
        "    if not annotations:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    data = []\n",
        "    for ann in annotations:\n",
        "        data.append({\n",
        "            'tcn_layers': video_name,\n",
        "            'Start Time': ann.get('start_time', ''),\n",
        "            'End Time': ann.get('end_time', ''),\n",
        "            'Event': ann.get('interaction_type', ''),\n",
        "            'Observations': ann.get('detailed_observations', ''),\n",
        "            'Dialogue Captured': ann.get('dialogue_captured', ''),\n",
        "            'Emotional Reaction': ann.get('emotional_reaction', ''),\n",
        "            'Initiation Action': '',  # Can be filled later if needed\n",
        "            'Ending Action': '',     # Can be filled later if needed\n",
        "            'Confidence': ann.get('confidence_score', 0.0)\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Gets Video Duration and Splits Into Chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kf4F8RQp3dEw"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "\n",
        "def get_video_duration_minutes(video_path):\n",
        "    \"\"\"Get actual video duration using ffprobe\"\"\"\n",
        "    try:\n",
        "        cmd = [\n",
        "            'ffprobe', '-v', 'quiet', '-print_format', 'json',\n",
        "            '-show_format', str(video_path)\n",
        "        ]\n",
        "        result = subprocess.run(cmd, capture_output=True, text=True, check=True)\n",
        "        info = json.loads(result.stdout)\n",
        "        duration_seconds = float(info['format']['duration'])\n",
        "        return duration_seconds / 60  # Convert to minutes\n",
        "    except:\n",
        "        # Fallback: estimate from file size (rough approximation)\n",
        "        file_size_gb = os.path.getsize(video_path) / (1024**3)\n",
        "        estimated_minutes = file_size_gb * 2.2  # Rough estimate: ~2.2 min per GB\n",
        "        print(f\"‚ö†Ô∏è Could not get exact duration, estimating ~{estimated_minutes:.0f} minutes\")\n",
        "        return estimated_minutes\n",
        "\n",
        "def check_file_size_and_decide_processing(video_path):\n",
        "    \"\"\"Check if file needs chunking and calculate optimal chunk duration - works for videos of all lengths\"\"\"\n",
        "    file_size_bytes = os.path.getsize(video_path)\n",
        "    file_size_gb = file_size_bytes / (1024**3)\n",
        "\n",
        "    print(f\"üìÅ Video file size: {file_size_gb:.2f} GB\")\n",
        "\n",
        "    # Gemini limit is 2GB\n",
        "    if file_size_bytes <= 1900000000:  # 1.9GB buffer\n",
        "        return False, file_size_gb, None\n",
        "\n",
        "    # Get actual video duration\n",
        "    video_duration_minutes = get_video_duration_minutes(video_path)\n",
        "    print(f\"‚è±Ô∏è Video duration: {video_duration_minutes:.1f} minutes\")\n",
        "\n",
        "    # Calculate chunks needed to stay under 1.8GB each\n",
        "    target_chunk_size_gb = 1.8\n",
        "    min_chunks_needed = int(file_size_gb / target_chunk_size_gb) + 1\n",
        "\n",
        "    # Calculate optimal chunk duration\n",
        "    optimal_chunk_minutes = max(2, int(video_duration_minutes / min_chunks_needed))\n",
        "\n",
        "    print(f\"üìä Need {min_chunks_needed} chunks of {optimal_chunk_minutes} minutes each\")\n",
        "\n",
        "    return True, file_size_gb, optimal_chunk_minutes\n",
        "\n",
        "def split_video_into_chunks(video_path, chunk_duration_minutes):\n",
        "    \"\"\"Split video into chunks under 2GB\"\"\"\n",
        "\n",
        "    print(f\"‚úÇÔ∏è Splitting into {chunk_duration_minutes}-minute chunks...\")\n",
        "\n",
        "    # Install ffmpeg if needed\n",
        "    try:\n",
        "        subprocess.run(['ffmpeg', '-version'], capture_output=True, check=True)\n",
        "    except:\n",
        "        print(\"üì¶ Installing FFmpeg...\")\n",
        "        subprocess.run(['apt', 'update', '-qq'], check=True)\n",
        "        subprocess.run(['apt', 'install', '-y', 'ffmpeg'], check=True)\n",
        "\n",
        "    # Create chunks directory\n",
        "    video_path = Path(video_path)\n",
        "    chunks_dir = video_path.parent / f\"{video_path.stem}_chunks\"\n",
        "    chunks_dir.mkdir(exist_ok=True)\n",
        "\n",
        "    # Split video\n",
        "    chunk_duration_seconds = chunk_duration_minutes * 60\n",
        "    output_pattern = str(chunks_dir / \"chunk_%03d.mp4\")\n",
        "\n",
        "    cmd = [\n",
        "        'ffmpeg', '-i', str(video_path),\n",
        "        '-c', 'copy',\n",
        "        '-map', '0',\n",
        "        '-segment_time', str(chunk_duration_seconds),\n",
        "        '-f', 'segment',\n",
        "        '-reset_timestamps', '1',\n",
        "        output_pattern,\n",
        "        '-y'\n",
        "    ]\n",
        "\n",
        "    print(\"üîÑ Splitting video...\")\n",
        "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
        "\n",
        "    if result.returncode != 0:\n",
        "        print(f\"‚ùå Video splitting failed: {result.stderr}\")\n",
        "        return []\n",
        "\n",
        "    # Get created chunks and verify sizes\n",
        "    chunk_files = sorted(list(chunks_dir.glob(\"chunk_*.mp4\")))\n",
        "\n",
        "    print(f\"‚úÖ Created {len(chunk_files)} chunks:\")\n",
        "    valid_chunks = []\n",
        "\n",
        "    for i, chunk in enumerate(chunk_files):\n",
        "        size_gb = os.path.getsize(chunk) / (1024**3)\n",
        "        size_mb = size_gb * 1024\n",
        "\n",
        "        if size_gb < 1.9:  # Under 1.9GB\n",
        "            print(f\"   ‚úÖ Chunk {i+1}: {size_mb:.0f} MB\")\n",
        "            valid_chunks.append(chunk)\n",
        "        else:\n",
        "            print(f\"   ‚ö†Ô∏è  Chunk {i+1}: {size_mb:.0f} MB (too large, skipping)\")\n",
        "\n",
        "    return valid_chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHO66JnJ3ghE"
      },
      "outputs": [],
      "source": [
        "def process_chunks_and_combine(chunk_files, original_video_name, chunk_duration_minutes=8):\n",
        "    \"\"\"Process all chunks and combine results with adjusted timestamps\"\"\"\n",
        "\n",
        "    print(f\"\\nüöÄ Processing {len(chunk_files)} chunks with Gemini...\")\n",
        "\n",
        "    all_annotations = []\n",
        "\n",
        "    for i, chunk_path in enumerate(chunk_files):\n",
        "        print(f\"\\n--- Processing Chunk {i+1}/{len(chunk_files)} ---\")\n",
        "\n",
        "        try:\n",
        "            # Upload chunk to Gemini\n",
        "            chunk_name = f\"{original_video_name}_chunk_{i+1}\"\n",
        "            uploaded_file = genai.upload_file(path=str(chunk_path), display_name=chunk_name)\n",
        "\n",
        "            # Wait for processing\n",
        "            print(\"‚è≥ Processing with Gemini...\")\n",
        "            while uploaded_file.state.name == \"PROCESSING\":\n",
        "                print(\".\", end=\"\")\n",
        "                time.sleep(5)\n",
        "                uploaded_file = genai.get_file(uploaded_file.name)\n",
        "\n",
        "            if uploaded_file.state.name == \"FAILED\":\n",
        "                print(f\"\\n‚ùå Chunk {i+1} processing failed\")\n",
        "                continue\n",
        "\n",
        "            print(f\"\\n‚úÖ Gemini processing complete!\")\n",
        "\n",
        "            # Analyze chunk with your existing function\n",
        "            annotations = analyze_video_with_gemini(uploaded_file)\n",
        "\n",
        "            # Adjust timestamps to reflect position in original video\n",
        "            chunk_start_minutes = i * chunk_duration_minutes\n",
        "\n",
        "            for ann in annotations:\n",
        "                # Parse current timestamp and add chunk offset\n",
        "                start_time = ann.get('start_time', '0:00')\n",
        "                end_time = ann.get('end_time', '0:00')\n",
        "\n",
        "                # Convert MM:SS to total minutes, add chunk offset\n",
        "                start_parts = start_time.split(':')\n",
        "                start_total_min = int(start_parts[0]) + chunk_start_minutes\n",
        "                start_sec = int(start_parts[1]) if len(start_parts) > 1 else 0\n",
        "\n",
        "                end_parts = end_time.split(':')\n",
        "                end_total_min = int(end_parts[0]) + chunk_start_minutes\n",
        "                end_sec = int(end_parts[1]) if len(end_parts) > 1 else 0\n",
        "\n",
        "                # Update timestamps to reflect original video timeline\n",
        "                ann['start_time'] = f\"{start_total_min}:{start_sec:02d}\"\n",
        "                ann['end_time'] = f\"{end_total_min}:{end_sec:02d}\"\n",
        "                ann['chunk_number'] = i + 1\n",
        "\n",
        "            all_annotations.extend(annotations)\n",
        "            print(f\"‚úÖ Chunk {i+1}: Found {len(annotations)} interactions\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Chunk {i+1} failed: {e}\")\n",
        "            continue\n",
        "\n",
        "    return all_annotations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LK2Si_CX3j-J"
      },
      "source": [
        "Box Auth Integration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nw77T-r13lQ-"
      },
      "outputs": [],
      "source": [
        "class BoxVideoDownloader:\n",
        "    def __init__(self, client_id, client_secret):\n",
        "        \"\"\"Initialize Box OAuth client\"\"\"\n",
        "        self.client_id = client_id\n",
        "        self.client_secret = client_secret\n",
        "        self.box_client = None\n",
        "\n",
        "    def authenticate_with_box(self):\n",
        "        \"\"\"Complete OAuth flow - opens browser for user login\"\"\"\n",
        "\n",
        "        print(\"üîê Starting Box OAuth 2.0 authentication...\")\n",
        "\n",
        "        # Create OAuth2 object\n",
        "        oauth = OAuth2(\n",
        "            client_id=self.client_id,\n",
        "            client_secret=self.client_secret\n",
        "        )\n",
        "\n",
        "        # Get authorization URL\n",
        "        auth_url, csrf_token = oauth.get_authorization_url('https://irl.tech.cornell.edu/auto-ethnography-vlm/box-oauth-redirect.html')\n",
        "\n",
        "        print(f\"\\nüåê PLEASE VISIT THIS URL TO AUTHORIZE:\")\n",
        "        print(f\"{auth_url}\")\n",
        "        print(\"\\nAfter you log in, you'll be redirected to a URL.\")\n",
        "        print(\"Copy the ENTIRE URL from your browser and paste it below:\")\n",
        "\n",
        "        # Get authorization code from user\n",
        "        redirect_url = input(\"\\nPaste the redirect URL here: \").strip()\n",
        "\n",
        "        try:\n",
        "            # Extract authorization code from URL\n",
        "            if 'code=' in redirect_url:\n",
        "                auth_code = redirect_url.split('code=')[1].split('&')[0]\n",
        "            else:\n",
        "                raise ValueError(\"No authorization code found in URL\")\n",
        "\n",
        "            # Exchange code for access token\n",
        "            access_token, refresh_token = oauth.authenticate(auth_code)\n",
        "\n",
        "            # Create Box client\n",
        "            self.box_client = Client(oauth)\n",
        "\n",
        "            # Test connection\n",
        "            user = self.box_client.user().get()\n",
        "            print(f\"\\n‚úÖ Successfully authenticated as: {user.name}\")\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Authentication failed: {e}\")\n",
        "            return False\n",
        "\n",
        "    def download_file_by_id(self, file_id, local_path):\n",
        "        \"\"\"Download Box file using file ID\"\"\"\n",
        "\n",
        "        if not self.box_client:\n",
        "            print(\"‚ùå Not authenticated with Box\")\n",
        "            return None\n",
        "\n",
        "        try:\n",
        "            # Get file object\n",
        "            file_obj = self.box_client.file(file_id).get()\n",
        "\n",
        "            print(f\"üì• Downloading: {file_obj.name}\")\n",
        "            print(f\"üìÅ File size: {file_obj.size / (1024**3):.2f} GB\")\n",
        "\n",
        "            # Download file\n",
        "            with open(local_path, 'wb') as local_file:\n",
        "                file_obj.download_to(local_file)\n",
        "\n",
        "            # Verify download\n",
        "            downloaded_size = os.path.getsize(local_path)\n",
        "            print(f\"‚úÖ Download complete: {downloaded_size / (1024**3):.2f} GB\")\n",
        "\n",
        "            return local_path\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Download failed: {e}\")\n",
        "            return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "323h50EJlAUU",
        "outputId": "2dd9206e-3521-461f-cd05-1a0bf124c409"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Deleting: box_video_1939554923607_chunk_9\n",
            "Deleting: box_video_1939554923607_chunk_3\n",
            "Deleting: box_video_1939554923607_chunk_2\n",
            "Deleting: box_video_1939554923607_chunk_1\n",
            "Deleting: box_video_1939549048509_chunk_13\n",
            "Deleting: box_video_1939549048509_chunk_12\n",
            "Deleting: box_video_1939549048509_chunk_11\n",
            "Deleting: box_video_1939549048509_chunk_10\n",
            "Deleting: box_video_1939549048509_chunk_9\n",
            "Deleting: box_video_1939549048509_chunk_8\n",
            "Deleting: box_video_1939549048509_chunk_7\n",
            "Deleting: box_video_1939549048509_chunk_6\n",
            "Deleting: box_video_1939549048509_chunk_5\n",
            "Deleting: box_video_1939549048509_chunk_4\n",
            "Deleting: box_video_1939549048509_chunk_3\n",
            "Deleting: box_video_1939549048509_chunk_2\n",
            "Deleting: box_video_1939549048509_chunk_1\n",
            "‚úÖ All files cleaned up!\n"
          ]
        }
      ],
      "source": [
        "# List and delete all files in your Gemini storage\n",
        "# Uncomment and run this block to clean up your Gemini cloud storage if needed, it would tell you if you have the storage is full!\n",
        "\n",
        "# files = genai.list_files()\n",
        "# for file in files:\n",
        "#     print(f\"Deleting: {file.display_name}\")\n",
        "#     genai.delete_file(file.name)\n",
        "# print(\"‚úÖ All files cleaned up!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4tGbmRSY3t_Y"
      },
      "outputs": [],
      "source": [
        "def complete_box_to_annotations_pipeline(box_file_id, output_excel_path):\n",
        "    \"\"\"\n",
        "    COMPLETE PIPELINE: Box OAuth ‚Üí Download ‚Üí Chunk if needed ‚Üí Gemini ‚Üí Excel\n",
        "\n",
        "    Args:\n",
        "        box_file_id: Box file ID (from the URL when viewing file in Box)\n",
        "        output_excel_path: Where to save final Excel annotations\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"üé¨ COMPLETE BOX-TO-ANNOTATIONS PIPELINE\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Step 1: Authenticate with Box\n",
        "    print(\"STEP 1: Box Authentication\")\n",
        "    downloader = BoxVideoDownloader(BOX_CLIENT_ID, BOX_CLIENT_SECRET)\n",
        "\n",
        "    if not downloader.authenticate_with_box():\n",
        "        print(\"‚ùå Box authentication failed\")\n",
        "        return None, None\n",
        "\n",
        "    # Step 2: Download video from Box\n",
        "    print(f\"\\nSTEP 2: Download Video from Box\")\n",
        "    temp_video_path = f\"/content/downloaded_video.mp4\"\n",
        "\n",
        "    downloaded_path = downloader.download_file_by_id(box_file_id, temp_video_path)\n",
        "\n",
        "    if not downloaded_path:\n",
        "        print(\"‚ùå Video download failed\")\n",
        "        return None, None\n",
        "\n",
        "    # Step 3: Check if chunking is needed\n",
        "    print(f\"\\nSTEP 3: Check File Size and Processing Method\")\n",
        "    needs_chunking, file_size_gb, chunk_duration = check_file_size_and_decide_processing(downloaded_path)\n",
        "\n",
        "    video_name = f\"box_video_{box_file_id}\"\n",
        "\n",
        "    if needs_chunking:\n",
        "        print(f\"üìÅ File is {file_size_gb:.2f} GB - using chunking method\")\n",
        "\n",
        "        # Step 4a: Split into chunks\n",
        "        print(f\"\\nSTEP 4: Split Video into Chunks\")\n",
        "        chunk_files = split_video_into_chunks(downloaded_path, chunk_duration)\n",
        "\n",
        "        if not chunk_files:\n",
        "            print(\"‚ùå Video chunking failed\")\n",
        "            return None, None\n",
        "\n",
        "        # Step 5a: Process chunks and combine\n",
        "        print(f\"\\nSTEP 5: Process Chunks with Gemini\")\n",
        "        all_annotations = process_chunks_and_combine(chunk_files, video_name)\n",
        "\n",
        "    else:\n",
        "        print(f\"‚úÖ File is {file_size_gb:.2f} GB - processing directly\")\n",
        "\n",
        "        # Step 4b: Process directly with Gemini\n",
        "        print(f\"\\nSTEP 4: Process Video with Gemini\")\n",
        "        uploaded_file = genai.upload_file(path=downloaded_path, display_name=video_name)\n",
        "\n",
        "        # Wait for processing\n",
        "        while uploaded_file.state.name == \"PROCESSING\":\n",
        "            print(\".\", end=\"\")\n",
        "            time.sleep(5)\n",
        "            uploaded_file = genai.get_file(uploaded_file.name)\n",
        "\n",
        "        # Analyze with your existing function\n",
        "        all_annotations = analyze_video_with_gemini(uploaded_file)\n",
        "\n",
        "    # Step 6: Create Excel output\n",
        "    print(f\"\\nSTEP 6: Create Excel Annotations\")\n",
        "\n",
        "    if all_annotations:\n",
        "        # Create DataFrame with your existing function\n",
        "        df = create_annotation_dataframe(all_annotations, video_name)\n",
        "\n",
        "        # Add chunk info if chunked\n",
        "        if needs_chunking:\n",
        "            chunk_numbers = [ann.get('chunk_number', 1) for ann in all_annotations]\n",
        "            df['Chunk_Number'] = chunk_numbers\n",
        "\n",
        "        # Save to Excel\n",
        "        df.to_excel(output_excel_path, index=False)\n",
        "\n",
        "        print(f\"‚úÖ SUCCESS!\")\n",
        "        print(f\"üìä Total interactions found: {len(all_annotations)}\")\n",
        "        print(f\"üíæ Results saved to: {output_excel_path}\")\n",
        "\n",
        "        # Show sample results\n",
        "        print(f\"\\nüìã SAMPLE INTERACTIONS:\")\n",
        "        for i in range(min(3, len(all_annotations))):\n",
        "            ann = all_annotations[i]\n",
        "            print(f\"{i+1}. {ann.get('start_time')}-{ann.get('end_time')}: {ann.get('interaction_type')}\")\n",
        "            print(f\"   Emotion: {ann.get('emotional_reaction')} (confidence: {ann.get('confidence_score', 0):.2f})\")\n",
        "            if ann.get('dialogue_captured'):\n",
        "                print(f\"   Quote: \\\"{ann.get('dialogue_captured', '')[:50]}...\\\"\")\n",
        "            print()\n",
        "    else:\n",
        "        print(\"‚ùå No interactions found\")\n",
        "        df, all_annotations = None, None\n",
        "\n",
        "    # Step 7: Clean up temporary files\n",
        "    print(f\"\\nSTEP 7: Cleanup\")\n",
        "    try:\n",
        "        os.remove(downloaded_path)\n",
        "        print(\"üóëÔ∏è Temporary video file cleaned up\")\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    return df, all_annotations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GnpqCFPO3xWL",
        "outputId": "e475e9c2-c94a-4dd5-b869-e1cf369d2229"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üöÄ READY TO PROCESS BOX VIDEOS!\n",
            "============================================================\n",
            "To get your Box file ID:\n",
            "1. Go to your video in Box web interface\n",
            "2. Look at the URL - it will be like: https://cornell.box.com/file/123456789\n",
            "3. The number at the end (123456789) is your file ID\n",
            "\n",
            "üé¨ COMPLETE BOX-TO-ANNOTATIONS PIPELINE\n",
            "============================================================\n",
            "STEP 1: Box Authentication\n",
            "üîê Starting Box OAuth 2.0 authentication...\n",
            "\n",
            "üåê PLEASE VISIT THIS URL TO AUTHORIZE:\n",
            "https://account.box.com/api/oauth2/authorize?state=box_csrf_token_Kri2GrJIuQzxJWmx&response_type=code&client_id=4w0jjxf4r496wt5vhyg10rkw243w0m61&redirect_uri=https%3A%2F%2Firl.tech.cornell.edu%2Fauto-ethnography-vlm%2Fbox-oauth-redirect.html\n",
            "\n",
            "After you log in, you'll be redirected to a URL.\n",
            "Copy the ENTIRE URL from your browser and paste it below:\n",
            "\n",
            "‚úÖ Successfully authenticated as: Audrey Tjokro\n",
            "\n",
            "STEP 2: Download Video from Box\n",
            "üì• Downloading: VID_20230924_153911_00_014.mp4\n",
            "üìÅ File size: 13.56 GB\n",
            "‚úÖ Download complete: 13.56 GB\n",
            "\n",
            "STEP 3: Check File Size and Processing Method\n",
            "üìÅ Video file size: 13.56 GB\n",
            "‚è±Ô∏è Video duration: 24.2 minutes\n",
            "üìä Need 8 chunks of 3 minutes each\n",
            "üìÅ File is 13.56 GB - using chunking method\n",
            "\n",
            "STEP 4: Split Video into Chunks\n",
            "‚úÇÔ∏è Splitting into 3-minute chunks...\n",
            "üîÑ Splitting video...\n",
            "‚úÖ Created 9 chunks:\n",
            "   ‚úÖ Chunk 1: 1722 MB\n",
            "   ‚úÖ Chunk 2: 1721 MB\n",
            "   ‚úÖ Chunk 3: 1721 MB\n",
            "   ‚úÖ Chunk 4: 1721 MB\n",
            "   ‚úÖ Chunk 5: 1721 MB\n",
            "   ‚úÖ Chunk 6: 1721 MB\n",
            "   ‚úÖ Chunk 7: 1721 MB\n",
            "   ‚úÖ Chunk 8: 1721 MB\n",
            "   ‚úÖ Chunk 9: 97 MB\n",
            "\n",
            "STEP 5: Process Chunks with Gemini\n",
            "\n",
            "üöÄ Processing 9 chunks with Gemini...\n",
            "\n",
            "--- Processing Chunk 1/9 ---\n",
            "‚è≥ Processing with Gemini...\n",
            "...................\n",
            "‚úÖ Gemini processing complete!\n",
            "Analyzing video with Gemini...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 71879.07ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 91165.80ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 66725.38ms\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"start_time\": \"00:00\",\n",
            "    \"end_time\": \"00:17\",\n",
            "    \"interaction_type\": \"talking\",\n",
            "    \"detailed_observations\": \"A woman with dark hair and glasses approaches the robot, holding a la...\n",
            "‚úÖ Chunk 1: Found 5 interactions\n",
            "\n",
            "--- Processing Chunk 2/9 ---\n",
            "‚è≥ Processing with Gemini...\n",
            ".....................\n",
            "‚úÖ Gemini processing complete!\n",
            "Analyzing video with Gemini...\n",
            "Raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"start_time\": \"00:00\",\n",
            "    \"end_time\": \"00:08\",\n",
            "    \"interaction_type\": \"approaching\",\n",
            "    \"detailed_observations\": \"A man and woman walk past the robot, pushing a wagon with a child...\n",
            "‚úÖ Chunk 2: Found 6 interactions\n",
            "\n",
            "--- Processing Chunk 3/9 ---\n",
            "‚è≥ Processing with Gemini...\n",
            "..................\n",
            "‚úÖ Gemini processing complete!\n",
            "Analyzing video with Gemini...\n",
            "Raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"start_time\": \"00:00\",\n",
            "    \"end_time\": \"00:02\",\n",
            "    \"interaction_type\": \"approaching\",\n",
            "    \"detailed_observations\": \"A woman with a child in a tricycle approaches the robot. She appe...\n",
            "‚úÖ Chunk 3: Found 4 interactions\n",
            "\n",
            "--- Processing Chunk 4/9 ---\n",
            "‚è≥ Processing with Gemini...\n",
            "..........................\n",
            "‚úÖ Gemini processing complete!\n",
            "Analyzing video with Gemini...\n",
            "Raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"start_time\": \"00:00\",\n",
            "    \"end_time\": \"00:13\",\n",
            "    \"interaction_type\": \"talking\",\n",
            "    \"detailed_observations\": \"Four people, three adults and a child, approach the robot. They appea...\n",
            "‚úÖ Chunk 4: Found 8 interactions\n",
            "\n",
            "--- Processing Chunk 5/9 ---\n",
            "‚è≥ Processing with Gemini...\n",
            "....................\n",
            "‚úÖ Gemini processing complete!\n",
            "Analyzing video with Gemini...\n",
            "Raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"start_time\": \"00:54\",\n",
            "    \"end_time\": \"01:02\",\n",
            "    \"interaction_type\": \"approaching\",\n",
            "    \"detailed_observations\": \"A family approaches the robot. The father is shirtless and pushin...\n",
            "‚úÖ Chunk 5: Found 3 interactions\n",
            "\n",
            "--- Processing Chunk 6/9 ---\n",
            "‚è≥ Processing with Gemini...\n",
            "....................\n",
            "‚úÖ Gemini processing complete!\n",
            "Analyzing video with Gemini...\n",
            "Raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"start_time\": \"00:30\",\n",
            "    \"end_time\": \"00:59\",\n",
            "    \"interaction_type\": [\"talking\", \"crowd_formation\"],\n",
            "    \"detailed_observations\": \"A group of four young adults and one older adult...\n",
            "‚úÖ Chunk 6: Found 2 interactions\n",
            "\n",
            "--- Processing Chunk 7/9 ---\n",
            "‚è≥ Processing with Gemini...\n",
            ".................\n",
            "‚úÖ Gemini processing complete!\n",
            "Analyzing video with Gemini...\n",
            "Raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"start_time\": \"00:04\",\n",
            "    \"end_time\": \"00:08\",\n",
            "    \"interaction_type\": \"talking\",\n",
            "    \"detailed_observations\": \"A man on a bicycle stops near the trash barrel robot. He looks at it,...\n",
            "‚úÖ Chunk 7: Found 5 interactions\n",
            "\n",
            "--- Processing Chunk 8/9 ---\n",
            "‚è≥ Processing with Gemini...\n",
            ".........................\n",
            "‚úÖ Gemini processing complete!\n",
            "Analyzing video with Gemini...\n",
            "Raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"start_time\": \"00:51\",\n",
            "    \"end_time\": \"01:15\",\n",
            "    \"interaction_type\": \"talking\",\n",
            "    \"detailed_observations\": \"A man in athletic wear approaches the robot and seems to be having a ...\n",
            "‚úÖ Chunk 8: Found 2 interactions\n",
            "\n",
            "--- Processing Chunk 9/9 ---\n",
            "‚è≥ Processing with Gemini...\n",
            "..\n",
            "‚úÖ Gemini processing complete!\n",
            "Analyzing video with Gemini...\n",
            "Raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"start_time\": \"00:00\",\n",
            "    \"end_time\": \"00:04\",\n",
            "    \"interaction_type\": \"talking\",\n",
            "    \"detailed_observations\": \"Two individuals walk past the robot.  One says \\\"All right\\\" in a neu...\n",
            "‚úÖ Chunk 9: Found 2 interactions\n",
            "\n",
            "STEP 6: Create Excel Annotations\n",
            "‚úÖ SUCCESS!\n",
            "üìä Total interactions found: 37\n",
            "üíæ Results saved to: /content/drive/MyDrive/HRI-Annotation/astoria-park-715-landfill-014.xlsx\n",
            "\n",
            "üìã SAMPLE INTERACTIONS:\n",
            "1. 0:00-0:17: talking\n",
            "   Emotion: positive (confidence: 0.80)\n",
            "   Quote: \"... maybe like the sprinklers... just got like a b...\"\n",
            "\n",
            "2. 0:20-0:31: talking\n",
            "   Emotion: neutral (confidence: 0.70)\n",
            "   Quote: \"... cause if somebody went there... I think if the...\"\n",
            "\n",
            "3. 0:51-2:09: talking\n",
            "   Emotion: neutral (confidence: 0.90)\n",
            "   Quote: \"... that tomorrow morning when you come back it wo...\"\n",
            "\n",
            "\n",
            "STEP 7: Cleanup\n",
            "üóëÔ∏è Temporary video file cleaned up\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(\"üöÄ READY TO PROCESS BOX VIDEOS!\")\n",
        "print(\"=\"*60)\n",
        "print(\"To get your Box file ID:\")\n",
        "print(\"1. Go to your video in Box web interface\")\n",
        "print(\"2. Look at the URL - it will be like: https://cornell.box.com/file/123456789\")\n",
        "print(\"3. The number at the end (123456789) is your file ID\")\n",
        "print()\n",
        "\n",
        "# CONFIGURE YOUR VALUES HERE:\n",
        "BOX_FILE_ID = \"1939554923607\"  # Replace with actual file ID\n",
        "OUTPUT_PATH = \"/content/drive/MyDrive/HRI-Annotation/astoria-park-715-landfill-014.xlsx\" # Where to save Excel file in your Google Drive\n",
        "\n",
        "# Uncomment the line below when you're ready to run:\n",
        "df, annotations = complete_box_to_annotations_pipeline(BOX_FILE_ID, OUTPUT_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6f553514"
      },
      "source": [
        "After installing the `boxsdk`, you can run the cell with the imports again."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
